{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiden/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cornac\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math, sys\n",
    "from dset import RecsysData, SequenceDataset\n",
    "from negative_sampler import NegativeSampler\n",
    "import random\n",
    "from model import BERTModel\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_100k = cornac.datasets.movielens.load_feedback(fmt='UIRT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['196' '186' '22' ... '276' '13' '12']\n",
      "['242' '302' '377' ... '1090' '225' '203']\n",
      "[3. 3. 1. ... 1. 2. 3.]\n",
      "[881250949 891717742 878887116 ... 874795795 882399156 879959583]\n"
     ]
    }
   ],
   "source": [
    "np_data = np.array(ml_100k)\n",
    "print(np_data[:,0])\n",
    "print(np_data[:,1])\n",
    "print(np_data[:,2].astype(float))\n",
    "print(np_data[:,3].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = pd.DataFrame({\n",
    "    'user_id': np_data[:,0],\n",
    "    'item_id': np_data[:,1],\n",
    "    'rating': np_data[:,2].astype(float),\n",
    "    'timestamp': np_data[:,3].astype(int)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   user_id    100000 non-null  object \n",
      " 1   item_id    100000 non-null  object \n",
      " 2   rating     100000 non-null  float64\n",
      " 3   timestamp  100000 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "pd_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [00:00<00:00, 4666.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myData = RecsysData(pd_data)\n",
    "myData.num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "\n",
    "trainset = SequenceDataset(\n",
    "    # Hyperparameters\n",
    "    max_len = max_len,\n",
    "    mask_prob = 0.15,\n",
    "    num_items = myData.num_items,\n",
    "    mask_token=myData.num_items + 1,    \n",
    "    u2seq=myData.train_seqs,\n",
    "    rng = random.Random(1234)\n",
    ")\n",
    "\n",
    "test_negative_sampler = NegativeSampler(\n",
    "    train=myData.train_seqs,\n",
    "    val=myData.val_seqs,\n",
    "    test=myData.test_seqs,\n",
    "    user_count=myData.num_users,\n",
    "    item_count=myData.num_items,\n",
    "    sample_size=99,\n",
    "    seed=1234,\n",
    "    save_folder=\"./Data/\",\n",
    ")\n",
    "test_negative_samples = test_negative_sampler.get_negative_samples()\n",
    "\n",
    "\n",
    "valset = SequenceDataset(\n",
    "    mask_token = myData.num_items + 1,\n",
    "    eval=True,\n",
    "    u2seq=myData.train_seqs,\n",
    "    u2answer=myData.val_seqs,\n",
    "    max_len = max_len,\n",
    "    negative_samples = test_negative_samples\n",
    ")\n",
    "\n",
    "mymodel = BERTModel(\n",
    "    hidden_size=256,\n",
    "    num_items=myData.num_items,     # item 的數量\n",
    "    n_layers=2,\n",
    "    dropout=0,\n",
    "    heads=8,\n",
    "    max_len=max_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    valset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = pl.Trainer(limit_train_batches=100, max_epochs=10, gpus=1)\n",
    "trainer.fit(mymodel, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70668f4c7653747fd59edaf7d5b50b4bbda7f2bf42a89fa403a332c71a486cbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
