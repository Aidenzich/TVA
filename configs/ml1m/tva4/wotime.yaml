data_class: ml1m.pkl
model_params:
  batch_size: 256
  d_model: 256
  dropout: 0.2
  heads: 8
  item_latent_factor:
    available: true
    hidden_dim: 256
    path: /home/VS6102093/thesis/TVA/logs/ml1m/vaeicf/d256/version_0/latent_factor/encode_result.npy
  mask_prob: 0.4
  max_len: 80
  n_layers: 2
  num_mask: 3
  # time_features:
  # - dayofweek
  # - months
  # - years
num_items: 3416
trainer_config:
  check_val_every_n_epoch: 50
  config_name: ml1m.tva4.28_len80_n3_m0.4
  devices:
  - 1
  ks:
  - 1
  - 5
  - 10
  - 20
  label_smoothing: 0.0
  limit_train_batches: 1.0
  lr: 0.001
  lr_scheduler: Warmup
  lr_scheduler_args:
    num_cycles: 0.2
    num_training_steps: 67000
    num_warmup_steps: 6000
  lr_scheduler_interval: step
  max_epochs: 250
  num_workers: 12
  seed: 0
  sliding_step: 10
  sliding_window: true
